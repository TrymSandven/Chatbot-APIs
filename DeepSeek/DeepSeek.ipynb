{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required libraries\n",
    "from openai import OpenAI\n",
    "import random\n",
    "import subprocess\n",
    "import pathlib\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import xmlrpc.client\n",
    "import time\n",
    "import re\n",
    "import base64\n",
    "import pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the API key from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=api_key, base_url=\"https://api.deepseek.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n"
     ]
    }
   ],
   "source": [
    "sys_instruction=\"All prompts should be answered with an in depth paper with an introduction, middle and end structured into chapters that is about 4 pages, written in markdown and include sources. Dont answer anything with less than 4 pages. Dont write anything other than the paper. Dont write ```markdown etc.\"\n",
    "topics = [\"technology\", \"science\", \"history\", \"art\", \"literature\", \"politics\", \"economics\", \"philosophy\"]\n",
    "\n",
    "plagiarism_score = 0\n",
    "version = 1\n",
    "file_path = f\"\"\n",
    "topic = \"\"\n",
    "\n",
    "for paper_number in range(1, 30):\n",
    "    topic = random.choice(topics)\n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    store=True,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": sys_instruction},\n",
    "        {\"role\": \"user\", \"content\": f\"Write a paper about {topic}. The specific topic is up to you.\"}\n",
    "    ]\n",
    "    )\n",
    "\n",
    "\n",
    "    try: \n",
    "        # Write the response to a file\n",
    "        with open(f\"outputs/{paper_number}_{topic}_version{version}.md\", \"a\") as f:\n",
    "            f.write(completion.choices[0].message.content)\n",
    "        file_path = f\"outputs/{paper_number}_{topic}_version{version}\"\n",
    "        print('Written to file')\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error writing to file: {e}\")\n",
    "\n",
    "    # Convert the markdown file to a PDF\n",
    "    command = f'pandoc \"{file_path}.md\" --pdf-engine=xelatex -o \"{file_path}.pdf'\n",
    "    subprocess.run(command, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# Authenticate with iThenticate\n",
    "load_dotenv()\n",
    "\n",
    "username = os.getenv(\"ITHENTICATE_USERNAME\")\n",
    "password = os.getenv(\"ITHENTICATE_PASSWORD\")\n",
    "\n",
    "url = \"https://api.ithenticate.com/rpc\"\n",
    "server = xmlrpc.client.ServerProxy(url)\n",
    "\n",
    "credentials = {\n",
    "    'username': username,\n",
    "    'password': password\n",
    "}\n",
    "\n",
    "response = server.login(credentials)\n",
    "sid = response['sid']\n",
    "sid_dict =  dict(sid = response['sid'])\n",
    "print(response['api_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder ID for 'Trym Master Thesis': {'folder': 4378261}\n"
     ]
    }
   ],
   "source": [
    "# Find the folder ID for 'Trym Master Thesis' folder\n",
    "response = server.folder.list(sid_dict)\n",
    "\n",
    "folder_id = None\n",
    "for folder in response.get('folders', []):\n",
    "    if folder.get('name') == 'Trym Master Thesis':\n",
    "        folder_id = folder.get('id')\n",
    "        break\n",
    "\n",
    "folder = dict(folder = folder_id)\n",
    "print(f\"Folder ID for 'Trym Master Thesis': {folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# Define the folder containing the PDFs\n",
    "folder_path = 'outputs'\n",
    "\n",
    "# Initialize the array to hold document data\n",
    "documents = []\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.pdf'):\n",
    "        # Extract the title from the filename (assuming the title is the filename without extension)\n",
    "        title = os.path.splitext(filename)[0]\n",
    "        \n",
    "        author_first = 'Hangzhou'\n",
    "        author_last = 'DeepSeek'\n",
    "        \n",
    "        # Read the PDF file and encode its content in base64\n",
    "        with open(os.path.join(folder_path, filename), 'rb') as pdf_file:\n",
    "            encoded_pdf = xmlrpc.client.Binary(pdf_file.read())\n",
    "        \n",
    "        # Create the document data dictionary\n",
    "        document_data = {\n",
    "            'title': title,\n",
    "            'author_first': author_first,\n",
    "            'author_last': author_last,\n",
    "            'filename': filename,\n",
    "            'upload': encoded_pdf\n",
    "        }\n",
    "        \n",
    "        # Add the document data to the array\n",
    "        documents.append(document_data)\n",
    "\n",
    "# Update the dictionary with the documents array\n",
    "arguments = dict(sid=sid, folder=folder_id, submit_to=1, uploads=documents)\n",
    "\n",
    "# Submit the documents to iThenticate\n",
    "response = server.document.add(arguments)\n",
    "print(response['api_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[115488120, 115488130, 115488112, 115488124, 115488114, 115488118, 115488122, 115488106, 115488127, 115488132, 115488131, 115488110, 115488128, 115488119, 115488125, 115488126, 115488121, 115488123, 115488116, 115488105, 115488111, 115488115, 115488107, 115488117, 115488101]\n"
     ]
    }
   ],
   "source": [
    "arguments = dict(sid=sid, id=folder_id)\n",
    "\n",
    "response = server.folder.get(arguments)\n",
    "# Extract document IDs and store them in a list\n",
    "document_ids = [doc['id'] for doc in response['documents'] if doc.get('author_last') == \"DeepSeek\"]\n",
    "\n",
    "print(document_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26_history_version1 has plagiarism score: 17%\n",
      "written to outputs/26_history_version2 to file\n",
      "Document uploaded to iThenticate\n",
      "7_science_version1 has plagiarism score: 28%\n",
      "written to outputs/7_science_version2 to file\n",
      "Document uploaded to iThenticate\n",
      "19_technology_version1 has plagiarism score: 19%\n",
      "written to outputs/19_technology_version2 to file\n",
      "Document uploaded to iThenticate\n",
      "2_economics_version1 has plagiarism score: 28%\n",
      "written to outputs/2_economics_version2 to file\n",
      "Document uploaded to iThenticate\n",
      "2_economics_version2 has plagiarism score: 11%\n",
      "written to outputs/2_economics_version3 to file\n",
      "Document uploaded to iThenticate\n",
      "20_history_version1 has plagiarism score: 16%\n",
      "written to outputs/20_history_version2 to file\n",
      "Document uploaded to iThenticate\n",
      "24_science_version1 has plagiarism score: 22%\n",
      "written to outputs/24_science_version2 to file\n",
      "Document uploaded to iThenticate\n",
      "24_science_version2 has plagiarism score: 26%\n",
      "written to outputs/24_science_version3 to file\n",
      "Document uploaded to iThenticate\n",
      "24_science_version3 has plagiarism score: 25%\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the document IDs\n",
    "for document_id in document_ids:\n",
    "    arguments = dict(sid=sid, id=document_id)\n",
    "    response = server.document.get(arguments)\n",
    "    plagiarism_score = response['documents'][0]['parts'][0]['score']\n",
    "    document_title = response['documents'][0]['title']\n",
    "    \n",
    "    # Extract the paper number and topic from the document title\n",
    "    match = re.match(r'^\\D*(\\d{1,2})', document_title)\n",
    "    paper_number = match.group(1) if match else ''\n",
    "    \n",
    "    match = re.search(r'_(.*?)_', document_title)\n",
    "    topic = match.group(1) if match else ''\n",
    "    \n",
    "    paper_version = int(document_title[-1])\n",
    "\n",
    "    # Check plagiarism score and generate a new paper if the score is above 10% a maximum of 10 times\n",
    "    for paper_version in range(1, 10):\n",
    "        #Check plagiarism score\n",
    "        if plagiarism_score >= 10:\n",
    "            print(f\"{document_title} has plagiarism score: {plagiarism_score}%\")\n",
    "        \n",
    "            # Path to the PDF file\n",
    "            doc_path = f\"outputs/{document_title}.pdf\"\n",
    "            \n",
    "            # Convert the PDF to text using PyMuPDF since DeepSeek does not support file upload\n",
    "            doc = pymupdf.open(doc_path)\n",
    "            for page in doc: # iterate the document pages\n",
    "                text = page.get_text() # get plain text encoded as UTF-8\n",
    "\n",
    "            # Generate a new paper based on the previous one\n",
    "            prompt = f\"You got got cought plagiarizing. The plagirism score was {plagiarism_score}%. Write the paper again to fix the plagiarism.\"\n",
    "            sys_instruction=\"All prompts should be answered with an in depth paper with an introduction, middle and end structured into chapters that is about 4 pages, written in markdown and include sources. Dont answer anything with less than 4 pages. Dont write anything other than the paper. The paper should be about the same topic as the previous one. With as few changes as possible.\"\n",
    "\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"deepseek-chat\",\n",
    "                store=True,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": sys_instruction},\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": f\"You got got cought plagiarizing. The plagirism score was {plagiarism_score}%. Write the paper again to fix the plagiarism. Here is the previous paper: {text}\",\n",
    "                            },\n",
    "                        ],\n",
    "                    },\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            try: \n",
    "                # Write the response to a file\n",
    "                file_path = f\"outputs/{paper_number}_{topic}_version{paper_version+1}\"\n",
    "                with open(f\"outputs/{paper_number}_{topic}_version{paper_version+1}.md\", \"a\") as f:\n",
    "                    f.write(completion.choices[0].message.content)\n",
    "\n",
    "                command = [\n",
    "                            \"pandoc\",\n",
    "                            f\"{file_path}.md\",\n",
    "                            \"--pdf-engine=xelatex\",\n",
    "                            \"-o\",\n",
    "                            f\"{file_path}.pdf\"\n",
    "                        ]\n",
    "\n",
    "                subprocess.run(command, check=True)\n",
    "                print(f\"written to {file_path} to file\")\n",
    "                \n",
    "                # Initialize the array to hold document data\n",
    "                documents = []\n",
    "            \n",
    "                title = f\"{paper_number}_{topic}_version{paper_version+1}\"\n",
    "                \n",
    "                author_first = 'Hangzhou'\n",
    "                author_last = 'DeepSeek'\n",
    "                \n",
    "                # Read the PDF file and encode its content in base64\n",
    "                with open(f\"outputs/{title}.pdf\", 'rb') as pdf_file:\n",
    "                    encoded_pdf = xmlrpc.client.Binary(pdf_file.read())\n",
    "                \n",
    "\n",
    "                # Create the document data dictionary\n",
    "                document_data = {\n",
    "                    'title': title,\n",
    "                    'author_first': author_first,\n",
    "                    'author_last': author_last,\n",
    "                    'filename': filename,\n",
    "                    'upload': encoded_pdf\n",
    "                }\n",
    "\n",
    "                # Add the document data to the array\n",
    "                documents.append(document_data)\n",
    "\n",
    "                # Update the test dictionary with the documents array\n",
    "                arguments = dict(sid=sid, folder=folder_id, submit_to=1, uploads=documents)\n",
    "\n",
    "                # Submit the documents to iThenticate\n",
    "                response = server.document.add(arguments)\n",
    "                document_id = response['uploaded'][0]['id']\n",
    "                print('Document uploaded to iThenticate')\n",
    "                time.sleep(20)\n",
    "                \n",
    "                arguments = dict(sid=sid, id=document_id)\n",
    "                response = server.document.get(arguments)\n",
    "\n",
    "                plagiarism_score = response['documents'][0]['parts'][0]['score']\n",
    "                document_title = response['documents'][0]['title']\n",
    "            except Exception as e:\n",
    "                print(f\"Error writing to file: {e}\")\n",
    "                pass\n",
    "        else:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
