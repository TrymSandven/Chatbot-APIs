{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required libraries\n",
    "from openai import OpenAI\n",
    "import random\n",
    "import subprocess\n",
    "import pathlib\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import xmlrpc.client\n",
    "import time\n",
    "import re\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the API key from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n"
     ]
    }
   ],
   "source": [
    "sys_instruction=\"All prompts should be answered with an in depth paper with an introduction, middle and end structured into chapters that is about 4 pages, written in markdown and include sources. Dont answer anything with less than 4 pages. Dont write anything other than the paper. Dont write ```markdown etc.\"\n",
    "topics = [\"technology\", \"science\", \"history\", \"art\", \"literature\", \"politics\", \"economics\", \"philosophy\"]\n",
    "\n",
    "plagiarism_score = 0\n",
    "version = 1\n",
    "file_path = f\"\"\n",
    "topic = \"\"\n",
    "\n",
    "for paper_number in range(1, 30):\n",
    "    topic = random.choice(topics)\n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    store=True,\n",
    "    messages=[\n",
    "        {\"role\": \"developer\", \"content\": sys_instruction},\n",
    "        {\"role\": \"user\", \"content\": f\"Write a paper about {topic}. The specific topic is up to you.\"}\n",
    "    ]\n",
    "    )\n",
    "\n",
    "\n",
    "    try: \n",
    "        # Write the response to a file\n",
    "        with open(f\"outputs/{paper_number}_{topic}_version{version}.md\", \"a\") as f:\n",
    "            f.write(completion.choices[0].message.content)\n",
    "        file_path = f\"outputs/{paper_number}_{topic}_version{version}\"\n",
    "        print('Written to file')\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error writing to file: {e}\")\n",
    "\n",
    "    # Convert the markdown file to a PDF\n",
    "    command = f'pandoc \"{file_path}.md\" --pdf-engine=xelatex -o \"{file_path}.pdf'\n",
    "    subprocess.run(command, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# Authenticate with iThenticate\n",
    "load_dotenv()\n",
    "\n",
    "username = os.getenv(\"ITHENTICATE_USERNAME\")\n",
    "password = os.getenv(\"ITHENTICATE_PASSWORD\")\n",
    "\n",
    "url = \"https://api.ithenticate.com/rpc\"\n",
    "server = xmlrpc.client.ServerProxy(url)\n",
    "\n",
    "credentials = {\n",
    "    'username': username,\n",
    "    'password': password\n",
    "}\n",
    "\n",
    "response = server.login(credentials)\n",
    "sid = response['sid']\n",
    "sid_dict =  dict(sid = response['sid'])\n",
    "print(response['api_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder ID for 'Trym Master Thesis': {'folder': 4378261}\n"
     ]
    }
   ],
   "source": [
    "# Find the folder ID for 'Trym Master Thesis' folder\n",
    "response = server.folder.list(sid_dict)\n",
    "\n",
    "folder_id = None\n",
    "for folder in response.get('folders', []):\n",
    "    if folder.get('name') == 'Trym Master Thesis':\n",
    "        folder_id = folder.get('id')\n",
    "        break\n",
    "\n",
    "folder = dict(folder = folder_id)\n",
    "print(f\"Folder ID for 'Trym Master Thesis': {folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# Define the folder containing the PDFs\n",
    "folder_path = 'outputs'\n",
    "\n",
    "# Initialize the array to hold document data\n",
    "documents = []\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.pdf'):\n",
    "        # Extract the title from the filename (assuming the title is the filename without extension)\n",
    "        title = os.path.splitext(filename)[0]\n",
    "        \n",
    "        author_first = 'OpenAI'\n",
    "        author_last = 'ChatGPT'\n",
    "        \n",
    "        # Read the PDF file and encode its content in base64\n",
    "        with open(os.path.join(folder_path, filename), 'rb') as pdf_file:\n",
    "            encoded_pdf = xmlrpc.client.Binary(pdf_file.read())\n",
    "        \n",
    "        # Create the document data dictionary\n",
    "        document_data = {\n",
    "            'title': title,\n",
    "            'author_first': author_first,\n",
    "            'author_last': author_last,\n",
    "            'filename': filename,\n",
    "            'upload': encoded_pdf\n",
    "        }\n",
    "        \n",
    "        # Add the document data to the array\n",
    "        documents.append(document_data)\n",
    "\n",
    "# Update the dictionary with the documents array\n",
    "arguments = dict(sid=sid, folder=folder_id, submit_to=1, uploads=documents)\n",
    "\n",
    "# Submit the documents to iThenticate\n",
    "response = server.document.add(arguments)\n",
    "print(response['api_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[115388832, 115388827, 115388840, 115388821, 115388841, 115388835, 115388816, 115388842, 115388837, 115388830, 115388824, 115388834, 115388833, 115388823, 115388829, 115388839, 115388822, 115388828, 115388820, 115388817, 115388836, 115388838, 115388825, 115388818, 115388814]\n"
     ]
    }
   ],
   "source": [
    "arguments = dict(sid=sid, id=folder_id)\n",
    "\n",
    "response = server.folder.get(arguments)\n",
    "# Extract document IDs and store them in a list\n",
    "document_ids = [doc['id'] for doc in response['documents'] if doc.get('author_last') == \"ChatGPT\"]\n",
    "\n",
    "print(document_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27_science_version1 has plagiarism score: 24%\n",
      "written to outputs/27_science_version2 to file\n",
      "Document uploaded to iThenticate\n",
      "27_science_version2 has plagiarism score: 27%\n",
      "written to outputs/27_science_version3 to file\n",
      "Document uploaded to iThenticate\n",
      "27_science_version3 has plagiarism score: 16%\n",
      "written to outputs/27_science_version4 to file\n",
      "Document uploaded to iThenticate\n",
      "27_science_version4 has plagiarism score: 15%\n",
      "written to outputs/27_science_version5 to file\n",
      "Document uploaded to iThenticate\n",
      "27_science_version5 has plagiarism score: 16%\n",
      "written to outputs/27_science_version6 to file\n",
      "Document uploaded to iThenticate\n",
      "27_science_version6 has plagiarism score: 19%\n",
      "written to outputs/27_science_version7 to file\n",
      "Document uploaded to iThenticate\n",
      "27_science_version7 has plagiarism score: 18%\n",
      "written to outputs/27_science_version8 to file\n",
      "Document uploaded to iThenticate\n",
      "27_science_version8 has plagiarism score: 25%\n",
      "written to outputs/27_science_version9 to file\n",
      "Document uploaded to iThenticate\n",
      "27_science_version9 has plagiarism score: 22%\n",
      "written to outputs/27_science_version10 to file\n",
      "Document uploaded to iThenticate\n",
      "17_science_version1 has plagiarism score: 21%\n",
      "written to outputs/17_science_version2 to file\n",
      "Document uploaded to iThenticate\n",
      "12_technology_version1 has plagiarism score: 16%\n",
      "written to outputs/12_technology_version2 to file\n",
      "Document uploaded to iThenticate\n",
      "4_philosophy_version1 has plagiarism score: 12%\n",
      "written to outputs/4_philosophy_version2 to file\n",
      "Document uploaded to iThenticate\n",
      "1_economics_version1 has plagiarism score: 11%\n",
      "written to outputs/1_economics_version2 to file\n",
      "Document uploaded to iThenticate\n",
      "19_economics_version1 has plagiarism score: 14%\n",
      "written to outputs/19_economics_version2 to file\n",
      "Document uploaded to iThenticate\n",
      "19_economics_version2 has plagiarism score: 12%\n",
      "written to outputs/19_economics_version3 to file\n",
      "Document uploaded to iThenticate\n",
      "18_economics_version1 has plagiarism score: 10%\n",
      "written to outputs/18_economics_version2 to file\n",
      "Document uploaded to iThenticate\n",
      "23_science_version1 has plagiarism score: 18%\n",
      "written to outputs/23_science_version2 to file\n",
      "Document uploaded to iThenticate\n",
      "16_science_version1 has plagiarism score: 12%\n",
      "written to outputs/16_science_version2 to file\n",
      "Document uploaded to iThenticate\n",
      "16_science_version2 has plagiarism score: 10%\n",
      "written to outputs/16_science_version3 to file\n",
      "Document uploaded to iThenticate\n",
      "5_technology_version1 has plagiarism score: 22%\n",
      "written to outputs/5_technology_version2 to file\n",
      "Document uploaded to iThenticate\n",
      "5_technology_version2 has plagiarism score: 18%\n",
      "written to outputs/5_technology_version3 to file\n",
      "Document uploaded to iThenticate\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the document IDs\n",
    "for document_id in document_ids:\n",
    "    arguments = dict(sid=sid, id=document_id)\n",
    "    response = server.document.get(arguments)\n",
    "    plagiarism_score = response['documents'][0]['parts'][0]['score']\n",
    "    document_title = response['documents'][0]['title']\n",
    "    \n",
    "    # Extract the paper number and topic from the document title\n",
    "    match = re.match(r'^\\D*(\\d{1,2})', document_title)\n",
    "    paper_number = match.group(1) if match else ''\n",
    "    \n",
    "    match = re.search(r'_(.*?)_', document_title)\n",
    "    topic = match.group(1) if match else ''\n",
    "    \n",
    "    paper_version = int(document_title[-1])\n",
    "\n",
    "    # Check plagiarism score and generate a new paper if the score is above 10% a maximum of 10 times\n",
    "    for paper_version in range(1, 10):\n",
    "        #Check plagiarism score\n",
    "        if plagiarism_score >= 10:\n",
    "            print(f\"{document_title} has plagiarism score: {plagiarism_score}%\")\n",
    "        \n",
    "            # Path to the PDF file\n",
    "            doc_path = f\"outputs/{document_title}.pdf\"\n",
    "            \n",
    "            # Read the PDF file bytes\n",
    "            with open(doc_path, 'rb') as doc:\n",
    "                data = doc.read()\n",
    "            base64_string = base64.b64encode(data).decode(\"utf-8\")\n",
    "\n",
    "            # Generate a new paper based on the previous one\n",
    "            prompt = f\"You got got cought plagiarizing. The plagirism score was {plagiarism_score}%. Write the paper again to fix the plagiarism.\"\n",
    "            sys_instruction=\"All prompts should be answered with an in depth paper with an introduction, middle and end structured into chapters that is about 4 pages, written in markdown and include sources. Dont answer anything with less than 4 pages. Dont write anything other than the paper. The paper should be about the same topic as the previous one. With as few changes as possible.\"\n",
    "\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                store=True,\n",
    "                messages=[\n",
    "                    {\"role\": \"developer\", \"content\": sys_instruction},\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"file\",\n",
    "                                \"file\": {\n",
    "                                    \"filename\": f\"{document_title}.pdf\",\n",
    "                                    \"file_data\": f\"data:application/pdf;base64,{base64_string}\",\n",
    "                                },\n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": f\"You got got cought plagiarizing. The plagirism score was {plagiarism_score}%. Write the paper again to fix the plagiarism.\",\n",
    "                            },\n",
    "                        ],\n",
    "                    },\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            try: \n",
    "                # Write the response to a file\n",
    "                file_path = f\"outputs/{paper_number}_{topic}_version{paper_version+1}\"\n",
    "                with open(f\"outputs/{paper_number}_{topic}_version{paper_version+1}.md\", \"a\") as f:\n",
    "                    f.write(completion.choices[0].message.content)\n",
    "\n",
    "                command = [\n",
    "                            \"pandoc\",\n",
    "                            f\"{file_path}.md\",\n",
    "                            \"--pdf-engine=xelatex\",\n",
    "                            \"-o\",\n",
    "                            f\"{file_path}.pdf\"\n",
    "                        ]\n",
    "\n",
    "                subprocess.run(command, check=True)\n",
    "                print(f\"written to {file_path} to file\")\n",
    "                \n",
    "                # Initialize the array to hold document data\n",
    "                documents = []\n",
    "            \n",
    "                title = f\"{paper_number}_{topic}_version{paper_version+1}\"\n",
    "                \n",
    "                author_first = 'OpenAI'\n",
    "                author_last = 'ChatGPT'\n",
    "                \n",
    "                # Read the PDF file and encode its content in base64\n",
    "                with open(f\"outputs/{title}.pdf\", 'rb') as pdf_file:\n",
    "                    encoded_pdf = xmlrpc.client.Binary(pdf_file.read())\n",
    "                \n",
    "\n",
    "                # Create the document data dictionary\n",
    "                document_data = {\n",
    "                    'title': title,\n",
    "                    'author_first': author_first,\n",
    "                    'author_last': author_last,\n",
    "                    'filename': filename,\n",
    "                    'upload': encoded_pdf\n",
    "                }\n",
    "\n",
    "                # Add the document data to the array\n",
    "                documents.append(document_data)\n",
    "\n",
    "                # Update the test dictionary with the documents array\n",
    "                arguments = dict(sid=sid, folder=folder_id, submit_to=1, uploads=documents)\n",
    "\n",
    "                # Submit the documents to iThenticate\n",
    "                response = server.document.add(arguments)\n",
    "                document_id = response['uploaded'][0]['id']\n",
    "                print('Document uploaded to iThenticate')\n",
    "                time.sleep(20)\n",
    "                \n",
    "                arguments = dict(sid=sid, id=document_id)\n",
    "                response = server.document.get(arguments)\n",
    "\n",
    "                plagiarism_score = response['documents'][0]['parts'][0]['score']\n",
    "                document_title = response['documents'][0]['title']\n",
    "            except Exception as e:\n",
    "                print(f\"Error writing to file: {e}\")\n",
    "                pass\n",
    "        else:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
