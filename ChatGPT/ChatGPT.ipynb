{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the required libraries\n",
    "from openai import OpenAI\n",
    "import random\n",
    "import subprocess\n",
    "import pathlib\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import xmlrpc.client\n",
    "import time\n",
    "import re\n",
    "import requests\n",
    "import pymupdf\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the API key from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Initial Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n",
      "Written to file\n"
     ]
    }
   ],
   "source": [
    "sys_instruction=\"All prompts should be answered with an in depth paper with an introduction, middle and end structured into chapters that is about 4 pages, written in markdown and include sources. Dont answer anything with less than 4 pages. Dont write anything other than the paper. Dont write ```markdown etc.\"\n",
    "topics = [\"technology\", \"science\", \"history\", \"art\", \"literature\", \"politics\", \"economics\", \"philosophy\"]\n",
    "\n",
    "plagiarism_score = 0\n",
    "version = 1\n",
    "file_path = f\"\"\n",
    "topic = \"\"\n",
    "\n",
    "for paper_number in range(1, 31):\n",
    "    topic = random.choice(topics)\n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    store=True,\n",
    "    messages=[\n",
    "        {\"role\": \"developer\", \"content\": sys_instruction},\n",
    "        {\"role\": \"user\", \"content\": f\"Write a paper about {topic}. The specific topic is up to you.\"}\n",
    "    ]\n",
    "    )\n",
    "\n",
    "\n",
    "    try: \n",
    "        # Write the response to a file\n",
    "        with open(f\"outputs/{paper_number}_{topic}_version{version}.md\", \"a\") as f:\n",
    "            f.write(completion.choices[0].message.content)\n",
    "        file_path = f\"outputs/{paper_number}_{topic}_version{version}\"\n",
    "        print('Written to file')\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error writing to file: {e}\")\n",
    "\n",
    "    # Convert the markdown file to a PDF\n",
    "    command = f'pandoc \"{file_path}.md\" --pdf-engine=xelatex -o \"{file_path}.pdf'\n",
    "    subprocess.run(command, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload initial files to iThenticate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# Authenticate with iThenticate\n",
    "load_dotenv()\n",
    "\n",
    "username = os.getenv(\"ITHENTICATE_USERNAME\")\n",
    "password = os.getenv(\"ITHENTICATE_PASSWORD\")\n",
    "\n",
    "url = \"https://api.ithenticate.com/rpc\"\n",
    "server = xmlrpc.client.ServerProxy(url)\n",
    "\n",
    "credentials = {\n",
    "    'username': username,\n",
    "    'password': password\n",
    "}\n",
    "\n",
    "response = server.login(credentials)\n",
    "sid = response['sid']\n",
    "sid_dict =  dict(sid = response['sid'])\n",
    "print(response['api_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder ID for 'Trym Master Thesis': {'folder': 4378261}\n"
     ]
    }
   ],
   "source": [
    "# Find the folder ID for 'Trym Master Thesis' folder\n",
    "response = server.folder.list(sid_dict)\n",
    "\n",
    "folder_id = None\n",
    "for folder in response.get('folders', []):\n",
    "    if folder.get('name') == 'Trym Master Thesis':\n",
    "        folder_id = folder.get('id')\n",
    "        break\n",
    "\n",
    "folder = dict(folder = folder_id)\n",
    "print(f\"Folder ID for 'Trym Master Thesis': {folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# Define the folder containing the PDFs\n",
    "folder_path = 'outputs'\n",
    "\n",
    "# Initialize the array to hold document data\n",
    "documents = []\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.pdf'):\n",
    "        # Extract the title from the filename (assuming the title is the filename without extension)\n",
    "        title = os.path.splitext(filename)[0]\n",
    "        \n",
    "        author_first = 'OpenAI'\n",
    "        author_last = 'ChatGPT'\n",
    "        \n",
    "        # Read the PDF file and encode its content in base64\n",
    "        with open(os.path.join(folder_path, filename), 'rb') as pdf_file:\n",
    "            encoded_pdf = xmlrpc.client.Binary(pdf_file.read())\n",
    "        \n",
    "        # Create the document data dictionary\n",
    "        document_data = {\n",
    "            'title': title,\n",
    "            'author_first': author_first,\n",
    "            'author_last': author_last,\n",
    "            'filename': filename,\n",
    "            'upload': encoded_pdf\n",
    "        }\n",
    "        \n",
    "        # Add the document data to the array\n",
    "        documents.append(document_data)\n",
    "\n",
    "# Update the dictionary with the documents array\n",
    "arguments = dict(sid=sid, folder=folder_id, submit_to=1, uploads=documents)\n",
    "\n",
    "# Submit the documents to iThenticate\n",
    "response = server.document.add(arguments)\n",
    "print(response['api_status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload initial files to Winston AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the API key from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "winston_api = os.getenv(\"WINSTON_API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{'name': '10_history_version1', 'score': 0}\n",
      "200\n",
      "{'name': '11_literature_version1', 'score': 0}\n",
      "200\n",
      "{'name': '12_literature_version1', 'score': 0}\n",
      "200\n",
      "{'name': '13_art_version1', 'score': 0}\n",
      "200\n",
      "{'name': '14_technology_version1', 'score': 0}\n",
      "200\n",
      "{'name': '15_history_version1', 'score': 0}\n",
      "200\n",
      "{'name': '15_history_version2', 'score': 0}\n",
      "200\n",
      "{'name': '16_history_version1', 'score': 0}\n",
      "200\n",
      "{'name': '17_economics_version1', 'score': 4}\n",
      "200\n",
      "{'name': '17_economics_version2', 'score': 0}\n",
      "200\n",
      "{'name': '18_literature_version1', 'score': 0}\n",
      "200\n",
      "{'name': '19_technology_version1', 'score': 0}\n",
      "200\n",
      "{'name': '19_technology_version2', 'score': 0}\n",
      "200\n",
      "{'name': '19_technology_version3', 'score': 0}\n",
      "200\n",
      "{'name': '1_literature_version1', 'score': 0}\n",
      "200\n",
      "{'name': '20_history_version1', 'score': 0}\n",
      "200\n",
      "{'name': '21_economics_version1', 'score': 0}\n",
      "200\n",
      "{'name': '22_economics_version1', 'score': 0}\n",
      "200\n",
      "{'name': '23_literature_version1', 'score': 0}\n",
      "200\n",
      "{'name': '24_science_version1', 'score': 0}\n",
      "200\n",
      "{'name': '25_economics_version1', 'score': 3}\n",
      "200\n",
      "{'name': '26_science_version1', 'score': 0}\n",
      "200\n",
      "{'name': '26_science_version2', 'score': 0}\n",
      "200\n",
      "{'name': '26_science_version3', 'score': 0}\n",
      "200\n",
      "{'name': '26_science_version4', 'score': 5}\n",
      "200\n",
      "{'name': '26_science_version5', 'score': 0}\n",
      "200\n",
      "{'name': '26_science_version6', 'score': 0}\n",
      "200\n",
      "{'name': '27_philosophy_version1', 'score': 0}\n",
      "200\n",
      "{'name': '28_economics_version1', 'score': 0}\n",
      "200\n",
      "{'name': '29_philosophy_version1', 'score': 0}\n",
      "200\n",
      "{'name': '2_philosophy_version1', 'score': 0}\n",
      "200\n",
      "{'name': '30_art_version1', 'score': 0}\n",
      "200\n",
      "{'name': '3_literature_version1', 'score': 0}\n",
      "200\n",
      "{'name': '4_science_version1', 'score': 5}\n",
      "200\n",
      "{'name': '4_science_version2', 'score': 0}\n",
      "200\n",
      "{'name': '5_science_version1', 'score': 0}\n",
      "200\n",
      "{'name': '5_science_version2', 'score': 0}\n",
      "200\n",
      "{'name': '6_economics_version1', 'score': 0}\n",
      "200\n",
      "{'name': '7_technology_version1', 'score': 0}\n",
      "200\n",
      "{'name': '7_technology_version2', 'score': 0}\n",
      "200\n",
      "{'name': '7_technology_version3', 'score': 0}\n",
      "200\n",
      "{'name': '8_history_version1', 'score': 0}\n",
      "200\n",
      "{'name': '9_science_version1', 'score': 2}\n",
      "200\n",
      "{'name': '9_science_version10', 'score': 0}\n",
      "200\n",
      "{'name': '9_science_version2', 'score': 0}\n",
      "200\n",
      "{'name': '9_science_version3', 'score': 0}\n",
      "200\n",
      "{'name': '9_science_version4', 'score': 0}\n",
      "200\n",
      "{'name': '9_science_version5', 'score': 0}\n",
      "200\n",
      "{'name': '9_science_version6', 'score': 0}\n",
      "200\n",
      "{'name': '9_science_version7', 'score': 0}\n",
      "200\n",
      "{'name': '9_science_version8', 'score': 0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 29\u001b[0m\n\u001b[0;32m     19\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: text,\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     23\u001b[0m }\n\u001b[0;32m     24\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBearer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwinston_api\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m }\n\u001b[1;32m---> 29\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(url, json\u001b[38;5;241m=\u001b[39mpayload, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[0;32m     30\u001b[0m response_data \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mstatus_code)\n",
      "File \u001b[1;32mc:\\Users\\trym1\\anaconda3\\Lib\\site-packages\\requests\\api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, data\u001b[38;5;241m=\u001b[39mdata, json\u001b[38;5;241m=\u001b[39mjson, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\trym1\\anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\trym1\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\trym1\\anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\trym1\\anaconda3\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    679\u001b[0m     )\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\trym1\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    788\u001b[0m     conn,\n\u001b[0;32m    789\u001b[0m     method,\n\u001b[0;32m    790\u001b[0m     url,\n\u001b[0;32m    791\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    792\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    793\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    794\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    795\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[0;32m    796\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[0;32m    797\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[0;32m    798\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[0;32m    800\u001b[0m )\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\trym1\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32mc:\\Users\\trym1\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py:516\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    513\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    515\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    519\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[1;32mc:\\Users\\trym1\\anaconda3\\Lib\\http\\client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1428\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\trym1\\anaconda3\\Lib\\http\\client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\trym1\\anaconda3\\Lib\\http\\client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\trym1\\anaconda3\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\trym1\\anaconda3\\Lib\\ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\trym1\\anaconda3\\Lib\\ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "url = \"https://api.gowinston.ai/v2/plagiarism\"\n",
    "# Define the folder containing the PDFs\n",
    "folder_path = 'outputs'\n",
    "\n",
    "scores = []\n",
    "\n",
    "# Initialize the array to hold document data\n",
    "documents = []\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.pdf'):\n",
    "        text = \"\"\n",
    "        doc = pymupdf.open(os.path.join(folder_path, filename)) # open the PDF file\n",
    "        for page in doc: # iterate the document pages\n",
    "            text += page.get_text() # get plain text encoded as UTF-8\n",
    "        title = os.path.splitext(filename)[0]\n",
    "\n",
    "        payload = {\n",
    "\n",
    "            \"text\": text,\n",
    "            \"language\": \"en\",\n",
    "        }\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {winston_api}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "\n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        response_data = response.json()\n",
    "        print(response.status_code)\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            score_data = {\n",
    "                \"name\": title,\n",
    "                \"score\": response_data[\"result\"][\"score\"]\n",
    "            }\n",
    "            scores.append(score_data)\n",
    "            print(score_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerun initial files if plagiarism score is >= 10 in iThenticate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[115565636, 115565649, 115565641, 115565640, 115565646, 115565637, 115565639, 115565651, 115565643, 115565627, 115565650, 115565647, 115565642, 115565633, 115565645, 115565648, 115565628, 115565629, 115565635, 115565638, 115565644, 115565626, 115565632, 115565624, 115565631]\n"
     ]
    }
   ],
   "source": [
    "arguments = dict(sid=sid, id=folder_id)\n",
    "\n",
    "response = server.folder.get(arguments)\n",
    "# Extract document IDs and store them in a list\n",
    "document_ids = [doc['id'] for doc in response['documents'] if doc.get('author_last') == \"ChatGPT\"]\n",
    "\n",
    "print(document_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7_technology_version1 has plagiarism score: 20%\n",
      "written to outputs/7_technology_version2 to file\n",
      "Document uploaded to iThenticate\n",
      "7_technology_version2 has plagiarism score: 11%\n",
      "written to outputs/7_technology_version3 to file\n",
      "Document uploaded to iThenticate\n",
      "4_science_version1 has plagiarism score: 15%\n",
      "written to outputs/4_science_version2 to file\n",
      "Document uploaded to iThenticate\n",
      "26_science_version1 has plagiarism score: 15%\n",
      "written to outputs/26_science_version2 to file\n",
      "Document uploaded to iThenticate\n",
      "26_science_version2 has plagiarism score: 14%\n",
      "written to outputs/26_science_version3 to file\n",
      "Document uploaded to iThenticate\n",
      "26_science_version3 has plagiarism score: 15%\n",
      "written to outputs/26_science_version4 to file\n",
      "Document uploaded to iThenticate\n",
      "26_science_version4 has plagiarism score: 16%\n",
      "written to outputs/26_science_version5 to file\n",
      "Document uploaded to iThenticate\n",
      "26_science_version5 has plagiarism score: 15%\n",
      "written to outputs/26_science_version6 to file\n",
      "Document uploaded to iThenticate\n",
      "9_science_version1 has plagiarism score: 28%\n",
      "written to outputs/9_science_version2 to file\n",
      "Document uploaded to iThenticate\n",
      "9_science_version2 has plagiarism score: 17%\n",
      "written to outputs/9_science_version3 to file\n",
      "Document uploaded to iThenticate\n",
      "9_science_version3 has plagiarism score: 15%\n",
      "written to outputs/9_science_version4 to file\n",
      "Document uploaded to iThenticate\n",
      "9_science_version4 has plagiarism score: 10%\n",
      "written to outputs/9_science_version5 to file\n",
      "Document uploaded to iThenticate\n",
      "9_science_version5 has plagiarism score: 17%\n",
      "written to outputs/9_science_version6 to file\n",
      "Document uploaded to iThenticate\n",
      "9_science_version6 has plagiarism score: 19%\n",
      "written to outputs/9_science_version7 to file\n",
      "Document uploaded to iThenticate\n",
      "9_science_version7 has plagiarism score: 23%\n",
      "written to outputs/9_science_version8 to file\n",
      "Document uploaded to iThenticate\n",
      "9_science_version8 has plagiarism score: 14%\n",
      "written to outputs/9_science_version9 to file\n",
      "Document uploaded to iThenticate\n",
      "9_science_version9 has plagiarism score: 21%\n",
      "written to outputs/9_science_version10 to file\n",
      "Document uploaded to iThenticate\n",
      "15_history_version1 has plagiarism score: 16%\n",
      "written to outputs/15_history_version2 to file\n",
      "Document uploaded to iThenticate\n",
      "5_science_version1 has plagiarism score: 21%\n",
      "written to outputs/5_science_version2 to file\n",
      "Document uploaded to iThenticate\n",
      "17_economics_version1 has plagiarism score: 14%\n",
      "written to outputs/17_economics_version2 to file\n",
      "Document uploaded to iThenticate\n",
      "19_technology_version1 has plagiarism score: 26%\n",
      "written to outputs/19_technology_version2 to file\n",
      "Document uploaded to iThenticate\n",
      "19_technology_version2 has plagiarism score: 11%\n",
      "written to outputs/19_technology_version3 to file\n",
      "Document uploaded to iThenticate\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the document IDs\n",
    "for document_id in document_ids:\n",
    "    arguments = dict(sid=sid, id=document_id)\n",
    "    response = server.document.get(arguments)\n",
    "    plagiarism_score = response['documents'][0]['parts'][0]['score']\n",
    "    document_title = response['documents'][0]['title']\n",
    "    \n",
    "    # Extract the paper number and topic from the document title\n",
    "    match = re.match(r'^\\D*(\\d{1,2})', document_title)\n",
    "    paper_number = match.group(1) if match else ''\n",
    "    \n",
    "    match = re.search(r'_(.*?)_', document_title)\n",
    "    topic = match.group(1) if match else ''\n",
    "    \n",
    "    paper_version = int(document_title[-1])\n",
    "\n",
    "    # Check plagiarism score and generate a new paper if the score is above 10% a maximum of 10 times\n",
    "    for paper_version in range(1, 10):\n",
    "        #Check plagiarism score\n",
    "        if plagiarism_score >= 10:\n",
    "            print(f\"{document_title} has plagiarism score: {plagiarism_score}%\")\n",
    "        \n",
    "            # Path to the PDF file\n",
    "            doc_path = f\"outputs/{document_title}.pdf\"\n",
    "            \n",
    "            # Read the PDF file bytes\n",
    "            with open(doc_path, 'rb') as doc:\n",
    "                data = doc.read()\n",
    "            base64_string = base64.b64encode(data).decode(\"utf-8\")\n",
    "\n",
    "            # Generate a new paper based on the previous one\n",
    "            prompt = f\"You got got cought plagiarizing. The plagirism score was {plagiarism_score}%. Write the paper again to fix the plagiarism.\"\n",
    "            sys_instruction=\"All prompts should be answered with an in depth paper with an introduction, middle and end structured into chapters that is about 4 pages, written in markdown and include sources. Dont answer anything with less than 4 pages. Dont write anything other than the paper. The paper should be about the same topic as the previous one. With as few changes as possible.\"\n",
    "\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                store=True,\n",
    "                messages=[\n",
    "                    {\"role\": \"developer\", \"content\": sys_instruction},\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"file\",\n",
    "                                \"file\": {\n",
    "                                    \"filename\": f\"{document_title}.pdf\",\n",
    "                                    \"file_data\": f\"data:application/pdf;base64,{base64_string}\",\n",
    "                                },\n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": f\"You got got cought plagiarizing. The plagirism score was {plagiarism_score}%. Write the paper again to fix the plagiarism.\",\n",
    "                            },\n",
    "                        ],\n",
    "                    },\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            try: \n",
    "                # Write the response to a file\n",
    "                file_path = f\"outputs/{paper_number}_{topic}_version{paper_version+1}\"\n",
    "                with open(f\"outputs/{paper_number}_{topic}_version{paper_version+1}.md\", \"a\") as f:\n",
    "                    f.write(completion.choices[0].message.content)\n",
    "\n",
    "                command = [\n",
    "                            \"pandoc\",\n",
    "                            f\"{file_path}.md\",\n",
    "                            \"--pdf-engine=xelatex\",\n",
    "                            \"-o\",\n",
    "                            f\"{file_path}.pdf\"\n",
    "                        ]\n",
    "\n",
    "                subprocess.run(command, check=True)\n",
    "                print(f\"written to {file_path} to file\")\n",
    "                \n",
    "                # Initialize the array to hold document data\n",
    "                documents = []\n",
    "            \n",
    "                title = f\"{paper_number}_{topic}_version{paper_version+1}\"\n",
    "                \n",
    "                author_first = 'OpenAI'\n",
    "                author_last = 'ChatGPT'\n",
    "                \n",
    "                # Read the PDF file and encode its content in base64\n",
    "                with open(f\"outputs/{title}.pdf\", 'rb') as pdf_file:\n",
    "                    encoded_pdf = xmlrpc.client.Binary(pdf_file.read())\n",
    "                \n",
    "\n",
    "                # Create the document data dictionary\n",
    "                document_data = {\n",
    "                    'title': title,\n",
    "                    'author_first': author_first,\n",
    "                    'author_last': author_last,\n",
    "                    'filename': filename,\n",
    "                    'upload': encoded_pdf\n",
    "                }\n",
    "\n",
    "                # Add the document data to the array\n",
    "                documents.append(document_data)\n",
    "\n",
    "                # Update the test dictionary with the documents array\n",
    "                arguments = dict(sid=sid, folder=folder_id, submit_to=1, uploads=documents)\n",
    "\n",
    "                # Submit the documents to iThenticate\n",
    "                response = server.document.add(arguments)\n",
    "                document_id = response['uploaded'][0]['id']\n",
    "                print('Document uploaded to iThenticate')\n",
    "                time.sleep(20)\n",
    "                \n",
    "                arguments = dict(sid=sid, id=document_id)\n",
    "                response = server.document.get(arguments)\n",
    "\n",
    "                plagiarism_score = response['documents'][0]['parts'][0]['score']\n",
    "                document_title = response['documents'][0]['title']\n",
    "            except Exception as e:\n",
    "                print(f\"Error writing to file: {e}\")\n",
    "                pass\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper_number: 10, topic: history, paper_version: 1\n",
      "paper_number: 11, topic: literature, paper_version: 1\n",
      "paper_number: 12, topic: literature, paper_version: 1\n",
      "paper_number: 13, topic: art, paper_version: 1\n",
      "paper_number: 14, topic: technology, paper_version: 1\n",
      "paper_number: 15, topic: history, paper_version: 1\n",
      "paper_number: 16, topic: history, paper_version: 1\n",
      "paper_number: 17, topic: economics, paper_version: 1\n",
      "paper_number: 18, topic: literature, paper_version: 1\n",
      "paper_number: 19, topic: technology, paper_version: 1\n",
      "paper_number: 1, topic: literature, paper_version: 1\n",
      "paper_number: 20, topic: history, paper_version: 1\n",
      "paper_number: 21, topic: economics, paper_version: 1\n",
      "paper_number: 22, topic: economics, paper_version: 1\n",
      "paper_number: 23, topic: literature, paper_version: 1\n",
      "paper_number: 24, topic: science, paper_version: 1\n",
      "paper_number: 25, topic: economics, paper_version: 1\n",
      "paper_number: 26, topic: science, paper_version: 1\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'outputs'\n",
    "# Iterate through the documents\n",
    "for element in scores:\n",
    "    # Extract the plagiarism score and document title\n",
    "    plagiarism_score = element['score']\n",
    "    document_title = element['name']\n",
    "    \n",
    "    # Define the regex pattern\n",
    "    pattern1 = r\"(\\d+)_([a-zA-Z]+)_version(\\d+)\"\n",
    "    pattern2 = r\"(\\d+)_([a-zA-Z]+)_version(\\d+)_winston\"\n",
    "\n",
    "    # Match the pattern for the first string\n",
    "    match_1 = re.match(pattern1, document_title)\n",
    "    match_2 = re.match(pattern2, document_title)\n",
    "    if match_1:\n",
    "        paper_number = match_1.group(1)\n",
    "        topic = match_1.group(2)\n",
    "        paper_version = match_1.group(3)\n",
    "\n",
    "    elif match_2:\n",
    "        paper_number = match_2.group(1)\n",
    "        topic = match_2.group(2)\n",
    "        paper_version = match_2.group(3)\n",
    "    else:\n",
    "        print(\"Error in matching the pattern for input_string_1\")\n",
    "\n",
    "\n",
    "    # Check plagiarism score and generate a new paper if the score is above 10% a maximum of 10 times\n",
    "    for paper_version in range(1, 10):\n",
    "        text = \"\"\n",
    "        #Check plagiarism score\n",
    "        if plagiarism_score >= 10:\n",
    "            print(f\"{document_title} has plagiarism score: {plagiarism_score}%\")\n",
    "        \n",
    "            # Path to the PDF file\n",
    "            doc_path = f\"outputs/{document_title}.pdf\"\n",
    "            \n",
    "            # Read the PDF file bytes\n",
    "            with open(doc_path, 'rb') as doc:\n",
    "                data = doc.read()\n",
    "            \n",
    "            base64_string = base64.b64encode(data).decode(\"utf-8\")\n",
    "\n",
    "            # Generate a new paper based on the previous one\n",
    "            prompt = f\"You got got cought plagiarizing. The plagirism score was {plagiarism_score}%. Write the paper again to fix the plagiarism.\"\n",
    "            sys_instruction=\"All prompts should be answered with an in depth paper with an introduction, middle and end structured into chapters that is about 4 pages, written in markdown and include sources. Dont answer anything with less than 4 pages. Dont write anything other than the paper. The paper should be about the same topic as the previous one. With as few changes as possible.\"\n",
    "\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                store=True,\n",
    "                messages=[\n",
    "                    {\"role\": \"developer\", \"content\": sys_instruction},\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"file\",\n",
    "                                \"file\": {\n",
    "                                    \"filename\": f\"{document_title}.pdf\",\n",
    "                                    \"file_data\": f\"data:application/pdf;base64,{base64_string}\",\n",
    "                                },\n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": f\"You got got cought plagiarizing. The plagirism score was {plagiarism_score}%. Write the paper again to fix the plagiarism.\",\n",
    "                            },\n",
    "                        ],\n",
    "                    },\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            try: \n",
    "                # Write the response to a file\n",
    "                file_path = f\"outputs/{paper_number}_{topic}_version{paper_version+1}_winston{plagiarism_score}\"\n",
    "                with open(f\"{file_path}.md\", \"a\") as f:\n",
    "                    f.write(response.text)\n",
    "                command = f'pandoc \"{file_path}.md\" --pdf-engine=xelatex -o \"{file_path}.pdf\"'\n",
    "                subprocess.run(command, shell=True, check=True)\n",
    "                print(f\"written {file_path} to file\")\n",
    "            \n",
    "                title = f\"{paper_number}_{topic}_version{paper_version+1}\"\n",
    "                \n",
    "                doc = pymupdf.open(os.path.join(folder_path, filename)) # open the PDF file\n",
    "                for page in doc: # iterate the document pages\n",
    "                    text += page.get_text() # get plain text encoded as UTF-8\n",
    "\n",
    "\n",
    "                payload = {\n",
    "\n",
    "                    \"text\": text,\n",
    "                    \"language\": \"en\",\n",
    "                }\n",
    "                headers = {\n",
    "                    \"Authorization\": f\"Bearer {winston_api}\",\n",
    "                    \"Content-Type\": \"application/json\"\n",
    "                }\n",
    "\n",
    "                response = requests.post(url, json=payload, headers=headers)\n",
    "                response_data = response.json()\n",
    "                # Check if the request was successful\n",
    "                if response.status_code == 200:\n",
    "                    score_data = {\n",
    "                        \"name\": filename,\n",
    "                        \"score\": response_data[\"result\"][\"score\"]\n",
    "                    }\n",
    "\n",
    "\n",
    "                plagiarism_score = response_data[\"result\"][\"score\"]\n",
    "                document_title = f\"{title}_winston{plagiarism_score}\"\n",
    "                print(f\"New Score: {document_title}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error writing to file: {e}\")\n",
    "                pass\n",
    "        else:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
